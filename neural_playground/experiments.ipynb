{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "itt = ift.train_set_from_dir('data/hadoop_images/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = ift.train_set_from_dir('data/hadoop_images/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = ift.train_set_from_dir('data/hadoop_images/train/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PIL.Image.open('data/0_200x200.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PIL.Image.open('data/1_200x200.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data/hadoop/test.java', 'rb') as test_java, open('data/hadoop/train.java', 'rb') as train_java:\n",
    "    test_text = test_java.read()\n",
    "    train_text = train_java.read()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX 1080 (CNMeM is disabled, cuDNN not available)\n"
     ]
    }
   ],
   "source": [
    "import autoencoders.images_from_text as ift\n",
    "reload(ift)\n",
    "import os\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import PIL.ImageFont\n",
    "import PIL.ImageOps\n",
    "import PIL.ImageDraw\n",
    "from keras.preprocessing.image import img_to_array, array_to_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (16, 1, 200, 200)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (16, 32, 200, 200)    320         input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (16, 1280000)         0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (16, 128)             163840128   flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (16, 2)               258         dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (16, 2)               258         dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)                ((16, 2), 2)          0           dense_2[0][0]                    \n",
      "                                                                   dense_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  ((16, 2), 128)        384         lambda_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  ((16, 2), 1280000)    165120000   dense_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)              ((16, 2), 32, 200, 2000           dense_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "deconvolution2d_1 (Deconvolution2((16, 2), 1, 200, 200)289         reshape_1[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 328961637\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.layers import Input, Dense, Lambda, Flatten, Reshape\n",
    "from keras.layers import Convolution2D, Deconvolution2D, MaxPooling2D\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras import objectives\n",
    "from keras.datasets import mnist\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols, img_chns = 200, 200, 1\n",
    "# number of convolutional filters to use\n",
    "nb_filters = 32\n",
    "# convolution kernel size\n",
    "nb_conv = 3\n",
    "\n",
    "batch_size = 16\n",
    "original_dim = (img_chns, img_rows, img_cols)\n",
    "latent_dim = 2\n",
    "intermediate_dim = 128\n",
    "epsilon_std = 0.01\n",
    "nb_epoch = 5\n",
    "\n",
    "\n",
    "x = Input(batch_shape=(batch_size,) + original_dim)\n",
    "c = Convolution2D(nb_filters, nb_conv, nb_conv, border_mode='same', activation='relu')(x)\n",
    "f = Flatten()(c)\n",
    "h = Dense(intermediate_dim, activation='relu')(f)\n",
    "\n",
    "z_mean = Dense(latent_dim)(h)\n",
    "z_log_var = Dense(latent_dim)(h)\n",
    "\n",
    "\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = K.random_normal(shape=(batch_size, latent_dim),\n",
    "                              mean=0., std=epsilon_std)\n",
    "    return z_mean + K.exp(z_log_var) * epsilon\n",
    "\n",
    "# note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "# so you could write `Lambda(sampling)([z_mean, z_log_var])`\n",
    "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
    "\n",
    "# we instantiate these layers separately so as to reuse them later\n",
    "decoder_h = Dense(intermediate_dim, activation='relu')\n",
    "decoder_f = Dense(nb_filters*img_rows*img_cols, activation='relu')\n",
    "decoder_c = Reshape((nb_filters, img_rows, img_cols))\n",
    "decoder_mean = Deconvolution2D(img_chns, nb_conv, nb_conv,\n",
    "                               (batch_size, img_chns, img_rows, img_cols),\n",
    "                               border_mode='same')\n",
    "\n",
    "h_decoded = decoder_h(z)\n",
    "f_decoded = decoder_f(h_decoded)\n",
    "c_decoded = decoder_c(f_decoded)\n",
    "x_decoded_mean = decoder_mean(c_decoded)\n",
    "\n",
    "\n",
    "def vae_loss(x, x_decoded_mean):\n",
    "    # NOTE: binary_crossentropy expects a batch_size by dim for x and x_decoded_mean, so we MUST flatten these!\n",
    "    x = K.flatten(x)\n",
    "    x_decoded_mean = K.flatten(x_decoded_mean)\n",
    "    xent_loss = objectives.binary_crossentropy(x, x_decoded_mean)\n",
    "    kl_loss = - 0.5 * K.mean(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "    return xent_loss + kl_loss\n",
    "\n",
    "vae = Model(x, x_decoded_mean)\n",
    "vae.compile(optimizer='rmsprop', loss=vae_loss)\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2000, 1, 28, 28), (6000, 1, 28, 28))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32')[:, None, :, :] / 255.\n",
    "x_test = x_test.astype('float32')[:, None, :, :] / 255.\n",
    "\n",
    "x_train = x_train[:6000, :]\n",
    "x_test = x_test[:2000, :]\n",
    "x_test.shape, x_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# x_train = test[:20000, :].astype('float32') / 255.\n",
    "# x_test = test[-4600:, :].astype('float32') / 255.\n",
    "x_train = test[:20000, :].astype('float32')[:, None, :, :] / 255.\n",
    "x_test = test[-4600:, :].astype('float32')[:, None, :, :] / 255.\n",
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vae.fit(x_train, x_train,\n",
    "        shuffle=True,\n",
    "        nb_epoch=1,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# build a model to project inputs on the latent space\n",
    "encoder = Model(x, z_mean)\n",
    "\n",
    "\n",
    "decoder_input = Input(shape=(latent_dim,))\n",
    "_h_decoded = decoder_h(decoder_input)\n",
    "_x_decoded_mean = decoder_mean(_h_decoded)\n",
    "new_img_generator = Model(decoder_input, _x_decoded_mean)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "from IPython.display import display\n",
    "for a in range(-200, 200, 100):\n",
    "    for b in range(-200, 200, 100):\n",
    "        ara = new_img_generator.predict(np.array([[a,b]]))\n",
    "        ima = array_to_img(ara.reshape((1, img_width, img_height))).resize((250, 250))\n",
    "        print a, b\n",
    "        display(ima)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
